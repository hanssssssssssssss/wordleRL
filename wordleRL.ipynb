{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bad11563",
   "metadata": {},
   "source": [
    "# Deep Q-Learning for Wordle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9e0617",
   "metadata": {},
   "source": [
    "#### Content\n",
    "1. The rules of the game\n",
    "2. The concept of Deep-Q-Learning\n",
    "3. Constructing the environment\n",
    "4. The architecture of the model\n",
    "5. Training results and tweaks\n",
    "6. Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aff0c5",
   "metadata": {},
   "source": [
    "# 1. The rules of wordle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252be6be",
   "metadata": {},
   "source": [
    "- Guess a five letter word in up to six attempts.\n",
    "- After eacht attempt: Feedback for letters that are at the correct position / somewhere else / not at all in the solution.\n",
    "- In the origibnal version: 12972 allowed guesswords, 2309 potential solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7d33fa",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deced0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordle import Wordle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35b963c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = \"bread\"\n",
    "game = Wordle(vocab=None, solution=solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6680589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<text style=background-color:yellow;font-size:large>a</text><text style=background-color:lightgrey;font-size:large>p</text><text style=background-color:lightgrey;font-size:large>p</text><text style=background-color:lightgrey;font-size:large>l</text><text style=background-color:yellow;font-size:large>e</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=background-color:lightgreen;font-size:large>b</text><text style=background-color:yellow;font-size:large>e</text><text style=background-color:yellow;font-size:large>r</text><text style=background-color:lightgrey;font-size:large>r</text><text style=background-color:lightgrey;font-size:large>y</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=background-color:lightgreen;font-size:large>b</text><text style=background-color:lightgreen;font-size:large>r</text><text style=background-color:yellow;font-size:large>a</text><text style=background-color:lightgrey;font-size:large>k</text><text style=background-color:yellow;font-size:large>e</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=background-color:lightgreen;font-size:large>b</text><text style=background-color:lightgreen;font-size:large>r</text><text style=background-color:lightgreen;font-size:large>e</text><text style=background-color:lightgreen;font-size:large>a</text><text style=background-color:lightgreen;font-size:large>d</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game over, you  won! Solution was: bread\n"
     ]
    }
   ],
   "source": [
    "game.play_visual(\"apple\")\n",
    "game.play_visual(\"berry\")\n",
    "game.play_visual(\"brake\")\n",
    "game.play_visual(\"bread\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d230a7",
   "metadata": {},
   "source": [
    "**Disclaimer:** This can be solved analytically with information theory. At each step there is an optimal guessword choice that minimizes entropy. But we're not here to do any of that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dc9c9e",
   "metadata": {},
   "source": [
    "After each guess, the game responds with one of $3^5$ seqeunces of green/yellow/grey-tiles. This means the potential number of different states per game is $(12972 * 3^5)^6 = 9.81 * 10^{38}$.  \n",
    "This is way too big to be explicitly represented in e.g. a Q-table.  \n",
    "&rarr; The expected reward has to be approximated by a parameterized function (a neural network) as a representation of policy π"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97caf8af",
   "metadata": {},
   "source": [
    "# 2. Deep-Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9dad2b",
   "metadata": {},
   "source": [
    "The idea behind Deep Q-Learning is to expand the single-step online updating of regular Q-learning with *experience replay* where the agent stores previous experience in a replay memory and periodically draws random samples from this memory to use as training data batches\n",
    "- Experience can potentially be used in many weight updates &rarr; greater data efficiency\n",
    "- Correlations between consecutive samples are broken &rarr; reduce the variance of updates\n",
    "- Experiences from other action-sequences are used &rarr; less susceptible to path dependencies in online training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1866c9e8",
   "metadata": {},
   "source": [
    "    Initialize action-value function Q with random weights\n",
    "    for episodes M do\n",
    "        for time t do  \n",
    "            With probability ε:                \n",
    "                select action aₜ randomly\n",
    "            else \n",
    "                select aₜ = max Q(φ(sₜ), θ)  \n",
    "            Execute action aₜ \n",
    "            Observe reward rₜ and state sₜ₊₁ \n",
    "            Store transition (sₜ, aₜ, rₜ, sₜ₊₁) in D  \n",
    "            Sample random minibatch (sₖ, aₖ, rₖ, sₖ₊₁) from replay memory\n",
    "            \n",
    "            if episode terminates in sₖ₊₁\n",
    "                yₖ = rₖ\n",
    "            else\n",
    "                Set yₖ = rₖ + γ  * max Q(φ(sₖ₊₁), θ) \n",
    "            Perform gradient descent step on (yₖ − Q(φₖ, θ))²"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb43eb4",
   "metadata": {},
   "source": [
    "# 3. Constructing the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50abae1d",
   "metadata": {},
   "source": [
    "### State space: \n",
    "- After each guess the game returns information for each letter at each position of the guessed word.\n",
    "- In the visual representation this is one of $3^5$ combinations of green/yellow/grey tiles.\n",
    "- The information of previus guesses should be included in the current state. This can be done e.g with a state vector of length $417$ that stores the following information:\n",
    "     - `state[0]` for the index of the current round.\n",
    "     - `state[1:26]` to remeber which letters have been guessed.\n",
    "     - After that: $5 * 26 * 3$ features for the green/yellow/grey-information of each letter in each position.\n",
    "         + Letter is definitely not in this spot: `[1, 0, 0]` \n",
    "         + Letter is maybe in this spot: `[0, 1, 0]`\n",
    "         + Letter is definitely in this spot: `[0, 0, 1]`\n",
    "- Reward can be given for correct letters and won games, negative reward for lost games.\n",
    "\n",
    "### Action space:\n",
    "- Originally: In each round any choice from the ~13k vocabulary is allowed. But only ~2.3k of these are poteniall solutions.\n",
    "- To reduce the size of the action space, this environment limits the vocabulary to words that are potenital solutions.  \n",
    "&rarr; The action space can be represented as a vector of vocabulary-length and interpreted eg. as a probability distribution for each word at the next round.\n",
    "\n",
    "### Reward:\n",
    "Balanced reward/cost for winnig and loosing:\n",
    "+ $- 50$ for a lost game\n",
    "+ $+ 50$ for a win"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d3796c",
   "metadata": {},
   "source": [
    "# 4. The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b9b98a",
   "metadata": {},
   "source": [
    "### General architecture\n",
    "- The used model is constructed as a linear network with one hidden layer of size 256 and stochastic gradient descent optimization.  \n",
    "- The model's input layer is of size $417$ to fit the state vector of the wordle environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ddc7d4",
   "metadata": {},
   "source": [
    "### The model output\n",
    "Each word from the vocabulary can be represented as a one hot encoded set of characters in each position, resulting in a vector of length $5 * 26 = 130$. This means the vocabulary itself can be represented as a matrix with 130 columns.  \n",
    "This allows for a model with one of the following two ways to predict the next action (= choose a word from the vocabulary)\n",
    "1. Use an output layer with a node for each word in the vocabulary\n",
    "    - Simplest way to obtain action probabilities\n",
    "    - The defining feature of a word is it's index position in the vocaulary\n",
    "2. Use an output layer of length 130 that is multiplied with the vocabulary matrix in the forwarding step\n",
    "    - The output layer can be semantically interpreted as weights for each letter and position\n",
    "    - Similar words get similarly activated\n",
    "    - The vocabulary can be shuffeled/changed  \n",
    "    &rarr; Allows warm-starting of agents for larger vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02a4714",
   "metadata": {},
   "source": [
    "# 5. Training results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec007e9",
   "metadata": {},
   "source": [
    "Training was started with a minimal variant of the problem setting for bugfixing and general proof of concept. Training on a 100 word vocabulary with 20 possible solutions shows good results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb07d1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "n_games = []\n",
    "recent_wins = []\n",
    "\n",
    "with open(\"stats/v100s20.txt\") as stats_small:\n",
    "    rows = csv.reader(stats_small, delimiter=\",\")\n",
    "    for row in rows:\n",
    "        n_games.append(int(row[0]))\n",
    "        recent_wins.append(int(row[1]))\n",
    "        total_winrate.append(float(row[2]))\n",
    "        \n",
    "plt.scatter(x=n_games, y=recent_wins)\n",
    "plt.xlabel(\"Number of games\")\n",
    "plt.ylabel(\"Wins per 100\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7d5e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8404da59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import Agent\n",
    "vocab_subset_len = 100\n",
    "random_seed = None\n",
    "with open(\"data/possible_words.txt\") as word_list:\n",
    "    vocab = word_list.read().split(\"\\n\")\n",
    "if vocab_subset_len:\n",
    "    random.seed(random_seed)\n",
    "    vocab = random.sample(vocab, k=vocab_subset_len)\n",
    "random.seed(random_seed)\n",
    "solution = random.choice(vocab)\n",
    "game = Wordle(vocab, 6, solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a2705d",
   "metadata": {},
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db09697",
   "metadata": {},
   "source": [
    "- Anderson, Benton et al. (2022): [Finding the optimal human strategy for Wordle using maximum correct letter probabilities and reinforcement learning](https://arxiv.org/abs/2202.00557)\n",
    "- Ho, Andrew (2022): [Solving Wordle with Reinforcement Learning](https://wandb.ai/andrewkho/wordle-solver/reports/Solving-Wordle-with-Reinforcement-Learning--VmlldzoxNTUzOTc4)\n",
    "- Loeber, Patrick (2022): [Train an AI to Play Snake](https://www.youtube.com/watch?v=L8ypSXwyBds) \n",
    "- Mnih, Volodymyr (2018): [Deep RL Bootcamp Lecture Deep Q-Networks](https://www.youtube.com/watch?v=fevMOp5TDQs)\n",
    "- Mnih, Volodymyr et al.(2013): [Playing Atari with Deep Reinforcement Learning](https://arxiv.org/abs/1312.5602)\n",
    "- Sanderson, Grant (2022): [Solving Wordle using information theory](https://www.youtube.com/watch?v=v68zYyaEmEA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d79c57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
